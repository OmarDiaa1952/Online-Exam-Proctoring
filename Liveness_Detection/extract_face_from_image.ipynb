{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-i', '--input', type=str, required=True,\n",
    "                    help='Path to input image')\n",
    "parser.add_argument('-o', '--output', type=str, required=True,\n",
    "                    help='Path to output directory of cropped face')\n",
    "parser.add_argument('-d', '--detector', type=str, required=True,\n",
    "                    help='Path to OpenCV\\'s face detector')\n",
    "parser.add_argument('-c', '--confidence', type=float, default=0.5,\n",
    "                    help='Confidence of face detection')\n",
    "args = vars(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[INFO] loading face detector')\n",
    "proto_path = os.path.sep.join([args['detector'],'deploy.prototxt'])\n",
    "model_path = os.path.sep.join([args['detector'],\n",
    "                               'res10_300x300_ssd_iter_140000.caffemodel'])\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(proto_path, model_path)\n",
    "\n",
    "# read the image\n",
    "image = cv2.imread(args['input'])\n",
    "\n",
    "# image name\n",
    "if len(os.listdir(args['output'])) > 0:\n",
    "    latest_file = 0\n",
    "    for file in os.listdir(args['output']):\n",
    "        latest_file = max(latest_file, int(file[:file.find('.')]))\n",
    "    # +1 so it doesn't replace the latest image in the directory\n",
    "    latest_file += 1\n",
    "else:\n",
    "    latest_file = 0\n",
    "    \n",
    "saved_name = latest_file\n",
    "\n",
    "# construct a blob from the image (preprocess image)\n",
    "# basically, it does mean subtraction and scaling\n",
    "# (104.0, 177.0, 123.0) is the mean of image in FaceNet\n",
    "h, w = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(image,(300,300)), 1.0,\n",
    "                             (300,300), (104.0, 177.0, 123.0))\n",
    "\n",
    "# pass the blob through the NN and obtain the detections\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "\n",
    "# ensure atleast 1 face it detected\n",
    "if len(detections) > 0:\n",
    "    # we're making the assumption that each image has ONLY ONE face,\n",
    "    # so find the bounding box with the largest probability\n",
    "    i = np.argmax(detections[0, 0, :, 2])\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    \n",
    "    # ensure that the detection with the highest probability \n",
    "    # pass our minumum probability threshold (helping filter out some weak detections)\n",
    "    if confidence > args['confidence']:\n",
    "        # compute the (x,y) coordinates of the bounding box\n",
    "        # for the face and extract face ROI\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype('int')\n",
    "        face = image[startY:endY, startX:endX]\n",
    "        \n",
    "        # write the image to disk\n",
    "        p = os.path.sep.join([args['output'], f'{saved_name}.png'])\n",
    "        cv2.imwrite(p, face)\n",
    "        print(f'[INFO] saved {p} to disk')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
